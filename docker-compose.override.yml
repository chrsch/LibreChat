services:
# USE LIBRECHAT CONFIG FILE
  api:
    depends_on:
      mongodb:
        condition: service_started
      rag_api:
        condition: service_started
      ollama:
        condition: service_healthy
      searxng:
        condition: service_started
    environment:
      - NODE_ENV=development # development mode allows http cookies for login
      - ALLOW_DEV_COOKIES=true # Required: npm script uses cross-env NODE_ENV=production, so this enables lax sameSite cookies for network access
      - SEARXNG_INSTANCE_URL=http://searxng:8080
      - FIRECRAWL_API_KEY=${FIRECRAWL_API_KEY}
      - JINA_API_KEY=${JINA_API_KEY}
    volumes:
    #- /home/christoph/Repositories/Github/chrsch/plantuml-mcp-server:/app/plantuml-mcp-server
    - type: bind
      source: ./librechat.yaml
      target: /app/librechat.yaml
    - type: bind
      source: ./api/server/services/AuthService.js
      target: /app/api/server/services/AuthService.js
  
  rag_api:
    image: ghcr.io/danny-avila/librechat-rag-api-dev:latest

  # ADD OLLAMA
  ollama:
    container_name: Ollama
    image: ollama/ollama:latest
    restart: always
    ports: ["11434:11434"]
    volumes:
      - ./ollama:/root/.ollama
      - ./ollama/init-ollama.sh:/usr/local/bin/init-ollama.sh:ro
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - OLLAMA_MODELS=${OLLAMA_MODELS}
    gpus: all
    entrypoint: ["/bin/bash", "/usr/local/bin/init-ollama.sh"]
    healthcheck:
      test: ["CMD", "sh", "-c", "ollama list | grep -q 'llama3.2-3b'"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 600s

# ADD SEARXNG for web search
  searxng:
    container_name: SearXNG
    image: searxng/searxng:latest
    restart: always
    ports:
      - "8080:8080"
    volumes:
      - ./searxng:/etc/searxng
    environment:
      - SEARXNG_BASE_URL=http://localhost:8080/


